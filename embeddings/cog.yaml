# Configuration for Cog ⚙️
# Reference: https://github.com/replicate/cog/blob/main/docs/yaml.md

build:
  # set to true if your model requires a GPU
  gpu: true
  cuda: "11.6"

  # a list of ubuntu apt packages to install
  system_packages:
    - "zlib1g"

  # python version in the form '3.8' or '3.8.12'
  python_version: "3.8"

  # a list of packages in the format <package-name>==<version>
  python_packages:
    - "torch==2.0.1"
    - "transformers==4.33.2"
    - "sentencepiece==0.1.99"
    - "accelerate==0.22.0"
    - "datasets==2.14.5"
    - "onnxruntime-gpu==1.15.0"
    - "fast-sentence-transformers[gpu]==0.4.1"
    - "hf_transfer==0.1.3"

  # commands run after the environment is setup
  run:
    - curl -o /usr/local/bin/pget -L "https://github.com/replicate/pget/releases/download/v0.0.2/pget" && chmod +x /usr/local/bin/pget
    # This is a hack to get around the two versions of onnxruntime installed. -q -q -q makes it not so chatty lol
    - pip uninstall onnxruntime onnxruntime-gpu -y && yes | pip install --no-cache onnxruntime-gpu==1.15.0 -q -q -q --exists-action i

# predict.py defines how predictions are run on your model
predict: "predict.py:Predictor"
